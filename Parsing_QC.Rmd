---
title: "Parsing QC"
author: "Ruben Schep"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output: 
  html_document:
    theme: journal #cerulean
    highlight: monochrome
    toc: true
    toc_float: true
    code_folding: show
  editor_options:
    chunk_output_type: console
---


# knitr document van Steensel lab

```{r}
StartTime <-Sys.time()
library(knitr)
opts_chunk$set(dev=c('png', 'pdf'), fig.path = file.path("figures/"))
pdf.options(useDingbats = FALSE)
```

# Introduction
After demultiplexing all the samples from the sequencing data, the data has been processed by the CRISPR-TRIP snakemake script. This script maps the barcodes from the iPCR (iPCR from 5 feb 2018). It calls the true barcodes with the starcode script for both the mutation and mapping reads. It call the mutations on all the mutation samples and spits them in mapped, unmapped and non genuine.

`zcat 4803_iPCR_2000_A_1_R1.fq.gz 4803_iPCR_2000_A_2_R1.fq.gz | gzip -c - > `
  `4803_iPCR_2000_A_R1.fq.gz ; `
`zcat 4803_iPCR_2000_A_1_R2.fq.gz 4803_iPCR_2000_A_2_R2.fq.gz | gzip -c - > `
  `4803_iPCR_2000_A_R2.fq.gz ; `
`zcat 4803_iPCR_2000_B_1_R1.fq.gz 4803_iPCR_2000_B_2_R1.fq.gz | gzip -c - > `
  `4803_iPCR_2000_B_R1.fq.gz ; `
`zcat 4803_iPCR_2000_B_1_R2.fq.gz 4803_iPCR_2000_B_2_R2.fq.gz | gzip -c - > `
  `4803_iPCR_2000_B_R2.fq.gz`
`zless ../data/raw/4803_iPCR_2000_A_R1.fq.gz`

Here we want to do a QC of the parsing of the mapping, the barcodes and mutations. We will load the statistics data of all the files. We will also look at barcode counts from the table files (those list the barcodes from the starcode stript). I obtained the counts though shell with 
`cd /DATA/projects/DSBrepair/data/rs20190705_TRIP/mutation`
`wc -l * > /DATA/projects/DSBrepair/data/rs20190705_TRIP/rs20190711_starcode_barcode_counts.txt`

Pasted the result in a text editor and changes all `^ ` and changed the spaces to `\t`, removed the last total row, removed `.table` at the end and saved as text file. 
I will export a bed file also containing the broad integrations for the generation of mean chip values over the integration sites. 

## Description of Data
The statistics files look like this for the mapping:
```{r table1, echo=FALSE, message=FALSE, warnings=FALSE, results="asis"}
tabl <- "
|	reads	|	bp	|	reads_written	|	bp_written	|	n_tooshort	|	index	|	map_pat1a	|	const_bar	|	rev_map_complement	|	rev_map	|	fwd_map_complement|
|----|----|----|----|----|----|----|----|----|----|----|
|19828607	|	5869267672	|	13923655	|	1901947251	|	0	|	19828607	|	19159557	|	14908545	|	8002804	|	13923655	|	7831360|

"
cat(tabl) # output the table in a format good for HTML/PDF/docx conversion
```

And like this for the mutations : 
```{r table2, echo=FALSE, message=FALSE, warnings=FALSE, results="asis"}
tabl <- "
|	reads	|	bp	|	reads_written	|	bp_written	|	n_tooshort	|	pat1	|	barcode	|	pat2|
|----|----|----|----|----|----|----|----|
|	1917323	|	268435236	|	1523275	|	146262106	|	0	|	1802163	|	1802150	|	1523275|
"
cat(tabl) # output the table in a format good for HTML/PDF/docx conversion
```

For the genuine (mapped and unmapped) and non-genuine barcode counts I will just get the line counts of the files.   

679811      indel_1_A_GFP_DMSO_t16.genuine_mapped  
695310      indel_1_A_GFP_DMSO_t16.genuine_unmapped  
452964      indel_1_A_GFP_DMSO_t16.not_genuine  
1828085    	indel_1_A_GFP_DMSO_t16.raw  
422130      indel_1_A_GFP_DMSO_t64.genuine_mapped  
331931    	indel_1_A_GFP_DMSO_t64.genuine_unmapped  
337248    	indel_1_A_GFP_DMSO_t64.not_genuine   

# Data loading and processing 

## Path, Libraries, Parameters and Useful Functions  

```{r setup, message=FALSE, warning=FALSE}
StartTime <-Sys.time()

# 6-digit Date tag:
Date <- substr(gsub("-","",Sys.time()),1,8)

# libraries:
library(plyr)
library(dplyr)
library(GenomicRanges)
library(RColorBrewer)
library(ggplot2)
library(tidyverse)
library(report)

## Select outdir
out.dir = paste0("/DATA/projects/DSBrepair/data/R/rs", Date, "/")
dir.create(out.dir)
```
 
## Custom functions  

Functions used in this script:   

```{r custon functions}
MakeGranges <- function(x) {
  x$end_pos <- as.numeric(as.character(x$start_pos+3))
  colnames(x) <- c("name",
                   "seqname", 
                   "strand", 
                   "start",
                   "total_mapped", 
                   "mapq_sum1", 
                   "reads1", 
                   "mapq_sum2", 
                   "reads2", 
                   "seq", 
                   "end")
  gr <- makeGRangesFromDataFrame(x, keep.extra.columns = T)
  return(gr)
}

BarcodeOverlap <- function(read1, read2) {
  counts <- c(nrow(read1), 
              nrow(read2), 
              sum(read2$barcode %in% read1$barcode), 
              sum(!read1$barcode %in% read2$barcode),
              sum(!read2$barcode %in% read1$barcode))
}
```

## Data loading  

These are data from the crispr-trip.snake script, and a text file that has has been obtained as explained above.  

```{r data loading}
# First I load the statistics data from the mapping.
file.list <- list.files(path = "/DATA/projects/DSBrepair/data/rs20200221_TRIP/parsed/", pattern="mapping*.*statistics.txt", full.names = TRUE)
mapping.statistics.list <- lapply(file.list, read.table, 
                                  header = TRUE)
names(mapping.statistics.list)<- gsub(".*/iPCR.mapping_(.*?)_Seq_Run1.statistics.txt", 
                                      "\\1", 
                                      file.list)
mapping.statistics.df <- do.call(rbind.data.frame, 
                                 mapping.statistics.list)

# I also want to load the mapping data
file.list <- list.files(path = "/DATA/projects/DSBrepair/data/rs20200221_TRIP/table/", pattern="*.table", full.names = TRUE)
mapping.list <- lapply(file.list, read.table,
                       header = TRUE)
names(mapping.list)<- gsub(".*/iPCR.mapping_2000([AB])_Seq_Run1(.*?).table", 
                           "\\1\\2", 
                           file.list)
# Unlist the dataframes into separate dataframes (A.1, A.2, etc)
list2env(mapping.list ,.GlobalEnv)

# load the statistics data from the indels.
file.list <- list.files(path = "/DATA/projects/DSBrepair/data/rs20200221_TRIP/parsed/", pattern="indel*.*statistics.txt", full.names = TRUE)
indel.statistics.list <- lapply(file.list, read.table, 
                                  header = TRUE)
names(indel.statistics.list)<- gsub(".*//indelPCR.indel_(.*?).statistics.txt", 
                                      "\\1", 
                                      file.list)
# stats with index
indel.statistics.list1 <- indel.statistics.list[which(lengths(indel.statistics.list) == 9)]
# stats without index 
indel.statistics.list2 <- indel.statistics.list[which(lengths(indel.statistics.list) == 8)]

# make DF out of both
indel.statistics.df1 <- do.call(rbind.data.frame, indel.statistics.list1)
indel.statistics.df2 <- do.call(rbind.data.frame, indel.statistics.list2)
# bind data frames without index column in df1
indel.statistics.df <- rbind(indel.statistics.df1[, c(1,3, 7:9)], indel.statistics.df2[, c(1,3, 6:8)]) 

# Load metadata
metadata <- read.table("/DATA/projects/DSBrepair/config/rs20200829_metadata_Repair_TRIP.txt", header = TRUE, stringsAsFactors = FALSE) %>% as_tibble()
```

## Some data pre-processing  

```{r preprocessing}
# For the read 1 and read 2 overlap I want to create a table with the number of overlapping barcodes, 
# and different ones for eacht read. After that I will only take the overlapping ones to check the 
# quality of the ligation.
# For this I would like to work with granges objects. Let"s create them.
grmapping.list <- lapply(FUN = MakeGranges, X = mapping.list)
grnames <- paste0(names(grmapping.list), ".gr")
names(grmapping.list) <- grnames
list2env(grmapping.list ,.GlobalEnv)

readsA <- BarcodeOverlap(A.1, A.2)
readsB <- BarcodeOverlap(B.1, B.2)
Read1Read2Overlap <- rbind(readsA, readsB)
colnames(Read1Read2Overlap) <- c("Read1", 
                                 "Read2",
                                 "Both", 
                                 "Only read1", 
                                 "Only read2")
```
  
# Analysis  

## Parsing QC  

This data is pulled form the statistics files in `/parsed/`  

Here we want to look at the porportion of reads that contain the sequences (constant and barcodes) that we expect.   
It"s an overall check of the PCR and sequencing quality.  

### Mapping parsing  

```{r mapping parsing QC}
#Plot the read statistics for the 2000 pool
barplot(as.matrix(t(mapping.statistics.df[,c(1,3,6:11)])), 
        col = brewer.pal(8, "Set1"),
        beside = T, 
        main = "Read parsing statistics", 
        ylab = "reads", 
        legend = colnames(mapping.statistics.df[,c(1,3,6:11)]), 
        args.legend = list(x = "topright", cex = 0.6))

# % of reads written from the total reads :
mapping.statistics.df$reads_written/mapping.statistics.df$reads*100

# Plot the overlap of the mappability of read 1 and read 2. 
barplot(as.matrix(t(Read1Read2Overlap)),
        col = brewer.pal(5, "Set1"),
        beside = T, 
        main = "Read 1 and Read 2 overlaps", 
        ylab = "Barcodes", 
        legend = colnames(Read1Read2Overlap),
        args.legend = list(x = "topright", cex = 0.70))
```

## Mapping QC  
Here we will have a look at the mapping quality and some conflicts.
These conflicts can be of different nature:
- mismatch in the barcode
- multiple alignments
- barcode present in both pools
 
### Diplicated integrations (mismatch in the barcode)  
  
```{r preprocess}
######################## Filtering the mapping files for mapping quality
# I need to filter for the correct mapping, ie. min 10 mapped reads, min 90% of 
# these reads on mapped on location 1 (freq1), and max 2.5% on location 2 (freq2)
mapping.df <- ldply(mapping.list, data.frame) %>% filter(mapq_sum1 != 0)
mapping.df$barcode <- paste(mapping.df$barcode, gsub("([AB])[.][12]", "\\1", mapping.df$.id), sep= ".")
mapping.df$mapq_1 <- mapping.df$mapq_sum1/mapping.df$reads1
mapping.df$mapq_2 <- mapping.df$mapq_sum2/mapping.df$reads2
mapping.df$freq1 <- mapping.df$reads1/mapping.df$total_mapped
mapping.df$freq2 <- mapping.df$reads2/mapping.df$total_mapped
dim(mapping.df)

mapping.plotting.df <- mapping.df %>% arrange(dplyr::desc(mapq_1))
ggplot(mapping.df, aes(mapq_1)) + geom_histogram(bins = 100) + geom_vline(xintercept = 10, color = "red") + theme_bw(base_size = 16)

filtered_mapping.df <- mapping.df[mapping.df$mapq_1 > 10 & 
                           mapping.df$total_mapped > 3 & 
                           mapping.df$freq1 > 0.70 & 
                           mapping.df$freq2 < 0.10, ]
filtered_mapping.df <- filtered_mapping.df %>% dplyr::select(-mapq_sum2, -reads2, -mapq_2, -freq2) # Remove mapq_sum, reads2, mapq2, freq2
dim(filtered_mapping.df)
head(filtered_mapping.df)
filtered_mapping.df <- filtered_mapping.df[with(filtered_mapping.df, order(start_pos, -mapq_1)), ]
```

#### Multimappers
Fist we should only get barcodes mapped twice in our setting. From read 1 and read 2. If we find them more than that, there"s a problem and we whould discard that barcode.
```{r }
# take only the barcode and the seq_name 
mappedbarcodes.df <- filtered_mapping.df [, c("barcode", "seqname")]
# count the barcode frequencies with table
mappedbarcodes.df <- as.data.frame(table(mappedbarcodes.df))
# remove the the 0 counts that were added with the table function. 
# (each barode has now a count for each chromosome - if it's not there it will be = 0)
mappedbarcodes.df <- mappedbarcodes.df[mappedbarcodes.df$Freq!=0, ]
# are there any barcodes that are mapped more than 2x to a chromosome ? 
mappedbarcodes.df[mappedbarcodes.df$Freq > 2, ]
```

There are no barcodes (when split A/B) that map more than 1x. (This is obvious, just a sanity check)

Then I want to check which barcodes are present in both pools. This is possible due to the setup of the experiment. For this we remove the .A and .B at the end of the barcode to pool them and repeat what we just did. 
```{r}
## What are the barcodes that are present in both A and B pools?
# take only the barcode and the seq_name 
mappedbarcodes.df <- filtered_mapping.df[, c("barcode", "seqname")]
# remove the .A and .B after the barcode.
mappedbarcodes.df$barcode <- gsub("\\..*","", mappedbarcodes.df$barcode)
# count the barcode frequencies with table
mappedbarcodes.df <- as.data.frame(table(mappedbarcodes.df)) 

# remove the counts of one barcode on another chromosome (this was added with the table function)
mappedbarcodes.df <- mappedbarcodes.df[mappedbarcodes.df$Freq!=0, ] 

# check if there are any barcodes that occur more than 2 times (2x + F and R read for each 
# pool, 4 occurences means the barcode is present in both pools)
mappedbarcodes.df[mappedbarcodes.df$Freq > 2, ] 
bothpools.vec <- as.character(mappedbarcodes.df[mappedbarcodes.df$Freq > 2, ]$barcode)
# These barcodes are present in both pool A and pool B.
bothpools.vec
# add the .A and .B again to see if they have similar read counts,
# which whould hint that they come from the same clone.
bothpools.vec <- c(paste0(bothpools.vec, ".A"), paste0(bothpools.vec, ".B"))
filtered_mapping.df[filtered_mapping.df$barcode %in% bothpools.vec, ]
nrow(filtered_mapping.df[filtered_mapping.df$barcode %in% bothpools.vec, ])/4

#with this way you will only find the barcodes that are mapped to the same location in both pools
```
Here we do find 9 barcodes that are in both pools. 
It is not clear if these barcode are from one clone of from several, it loook like there are at least 2 clones that are present in both the A and B pools.
One very abundant in B (3 barcodes), one the other 6 are more equal, which could be from 2-3 clones when looking at the numbers. This is a good reason I think to keep the barcodes anotated with A and B. 

### Manual curation
Are there duplicated start positions. Basically the same integration but with a different barcode (due to sequencing/PCR errors)?  
```{r}
# Get all the locations that are at least once duplicated
dupli.vec <- unique(filtered_mapping.df[duplicated(filtered_mapping.df$start_pos, 
                                                   fromLast=TRUE), 
                                        "start_pos" ])
# Filter the mapping data frame on these positions to get all of them 
# The duplicated function only returns the "extra" ones
dupli.df <- filtered_mapping.df %>% filter(start_pos %in% dupli.vec)
# how many duplicated integrations do we have ? 
nrow(dupli.df)
# Remove the set of intergrations that are both in the A and B pools (from this set). Because these are not multimappers in this case. 
dupli.df <- dupli.df[!dupli.df$barcode %in% bothpools.vec, ]
# How many duplications are we left with? 
nrow(dupli.df)
# as you can see the duplicated ones all have a lot of reads in one of the barcodes and very
#few in the others, we can retrieve the barcodes from this list to remove them from the mapping
# list. This is the list: 
dupli.df[ , c(1:6)]
# What we see it that most are duplicated sites due to a small barcode mismatch.

# Pick out the barcodes with less than 20 reads. They are the wrongs ones. 
# (Very similar barcodes, that weren"t filtered out by starcode)
dupli.bc.vec <- dupli.df %>% filter(total_mapped < 20) %>% pull(barcode)

dupli.df[!dupli.df$barcode %in% dupli.bc.vec,  c(1:6)] %>% arrange(barcode)
# there is one last duplicate in there, but has a good amount of reads, 
# let"s keep it as it may have many indel reads too.
filtered_mapping.df <- filtered_mapping.df[!filtered_mapping.df$barcode %in% 
                                           dupli.bc.vec, ]
dupli.vec.test <- unique(filtered_mapping.df[duplicated(filtered_mapping.df$start_pos, 
                                                        fromLast=TRUE), 
                                             "start_pos" ])
length(dupli.vec.test)


# Are most of these duplicated the ones from the cells in both pools? 
filtered_mapping.df %>% filter(start_pos %in% dupli.vec.test & 
                                 !barcode %in% bothpools.vec)
```

Yes, the data looks good like this. There are only 6 barcodes that are mapped exactly to the same location (3), two in A & B with different barcodes, and one with similar looking BC only in A due to two differnt sequences (maybe a snp at the GAT[A/C] where the sequence is cut).

We end up with this many integrations (taking into account only read 2):
```{r}
# how many site do we get (only taking into account read2)
nrow(filtered_mapping.df[filtered_mapping.df$.id %in% c("B.2", "A.2"), ])
```


### Differential mapping of certain integrations.  
Before we go further I wanted to check what distance we should expect to have similar mapping.    
```{r}
# Next I want to check if both reads map to the same chromosome
distance_mapping.df <- filtered_mapping.df[, c(".id", 
                                               "barcode", 
                                               "seqname", 
                                               "ori", 
                                               "start_pos", 
                                               "total_mapped")]
# Hereh we filter out the barcodes that at least have read1 AND read2. This means that they should be twice at least in the table. 
# We filter these out because we can"t measure distances with just one value...
FandR_reads.vec <- unique(filtered_mapping.df[duplicated(filtered_mapping.df$barcode, 
                                                         fromLast=TRUE), 
                                              "barcode" ])

tib_distance_mapping <- as_tibble(distance_mapping.df[distance_mapping.df$barcode %in% 
                                                        FandR_reads.vec, ])

tib_dist <- tib_distance_mapping %>% 
  dplyr::select(.id, barcode, start_pos) %>% 
  group_by(barcode) %>% 
  dplyr::summarise(dist = diff(start_pos))

tib_dist$trans <- as.integer(tib_dist$dist > 1000)

# I can quickly visualise how close read 1 and 2 align. Here I plot the amount of barcodes
# that have a set distance
ggplot(tib_dist, aes(barcode, sort(log10(dist)))) + 
  geom_bar(stat = "identity") + 
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())

# Which are the barcodes that map so far ? 
head(arrange(tib_dist, dplyr::desc(dist)), n = 10L)
tib_longdist <- tib_dist %>% filter(dist > 1200)
vec_longdistBC <- tib_longdist$barcode

# Let"s check those on the distance mapping data frame.
arrange(filtered_mapping.df[filtered_mapping.df$barcode %in% vec_longdistBC, ], barcode)
length(vec_longdistBC)

length(vec_longdistBC)/nrow(tib_dist)
```


There is a good amount of barcodes that have F and R reads in close proximity (max 1kb away). The 17 integrations (out of 2076) that have higher distances also map to different chromosomes, these were bad ligations and we trust the reverse read the the correct integration (read .2).

The ratio of bad ligations is very low here (< 1%), already visible from plot 2 in the mapping QC. 

# Data output pour the next scripts
We need a dataframe with all the barcodes of the confirmed integrations (with the extra info in case). The mapped barcodes from read 2 (A.2 and B.2)
```{r}
# Filter out the mapping from read 1, keep read 2. 
mapped.integrations.df <- filtered_mapping.df[filtered_mapping.df$.id %in% c("B.2", "A.2"), ]
mapped.integrations.df$seqname <- as.character(mapped.integrations.df$seqname)


# Add two mapped sites that were found with Tagmentation mapping & confirmed with sanger sequencing: 
# CATTTCTGATCAATAA.B  chr7	13259711	13259714	RSTP2_5	0	-
# ATACTATATTTAACGG.B  chr20	18569153	18569156	RSTP2_5	0	+
extra.mapped.sites.df <- data.frame(".id" = c("B.2", "B.2"),
                                    "barcode" =  c("CATTTCTGATCAATAA.B", "ATACTATATTTAACGG.B"),
                                    "seqname" = c("chr7", "chr20"),
                                    "ori" = c("-", "+"),
                                    "start_pos" = c(13259711, 18569153),
                                    "total_mapped" = c(NA, NA), 
                                    "mapq_sum1" = c(NA, NA),
                                    "reads1" = c(NA, NA), 
                                    "seq" = c(NA, NA),
                                    "mapq_1" = c(NA, NA),
                                    "freq1" = c(NA, NA))

mapped.integrations.df <- rbind(mapped.integrations.df, extra.mapped.sites.df)


# Make start and end 1kb apart.
# mapped.integrations.df$end_pos <- mapped.integrations.df$start_pos+1
# mapped.integrations.df$start_pos <- mapped.integrations.df$start_pos-500

# Organise the columns for bed file export.
bed.mapped.integrations.df <- mapped.integrations.df[, c("seqname", 
                                                         "start_pos", 
                                                         "barcode", 
                                                         "ori")]

write.table(bed.mapped.integrations.df, "/DATA/projects/DSBrepair/data/rs20190705_TRIP/rs20190711_mappedintegrations.tsv", sep = "\t", quote = FALSE)

# Let"s export this data frame to a bed file for the means chip script and hidden domains from christ
filename <- paste0(out.dir, "_Mapping_RSTP2_2000.bed")
write.table(bed.mapped.integrations.df, 
            file=filename, 
            quote=F, 
            sep="\t", 
            row.names=F, 
            col.names=F)

# Let"s also make a data file for the chromatin analysis.
analysis.mapped.integrations.df <- mapped.integrations.df[, c("seqname", 
                                                              "start_pos", 
                                                              # "end_pos", 
                                                              "ori", 
                                                              "barcode", 
                                                              "reads1", 
                                                              "mapq_1", 
                                                              "freq1")]
names(analysis.mapped.integrations.df)[2:3] <- c("start", "ori")

filename <- paste0(out.dir, "Analyis_Mapping_RSTP2_2000.txt")
write.table(analysis.mapped.integrations.df, 
            file=filename, 
            quote=F, 
            sep="\t", 
            row.names=F, 
            col.names=T)

# RData for the next scripts
filename <- paste0(out.dir, "Analyis_Mapping_RSTP2_2000.RData")
save(analysis.mapped.integrations.df, file = filename)
```

## Indel data statistics
```{r indel stats}
indel.statistics.tib <- indel.statistics.df %>% 
  rownames_to_column() %>% 
  as_tibble() %>% 
  mutate(discarded_reads = 1-reads_written/reads)

exps <- indel.statistics.tib %>% pull(rowname) %>% unique()
# select the used experiments
used_exps <- exps[grep("Clone5GSKBIX|LBR2GSKBIXRep3|LBR2Rep1a|LBR2Rep1b|Perturb|LMNAKOold|MultiPlateTS|XV|siRNAPoolRep|GFP|noguide|88|92|96", exps, invert = T)]
used_exps_fullname <- indel.statistics.tib$rowname[indel.statistics.tib$rowname %in% used_exps]


indel.statistics.filtered.tib <- indel.statistics.tib %>% 
  filter(rowname %in% used_exps_fullname) %>%
  mutate(rowname = gsub("_Seq_Run[123]$", "", rowname, perl = TRUE)) %>% 
  group_by(rowname) %>%
  dplyr::summarise(sum_r = sum(reads),
                   sum_rw = sum(reads_written)) %>% 
  mutate(discarded_reads = 1-sum_rw/sum_r)



ggplot(indel.statistics.tib, aes(discarded_reads)) + geom_histogram()
ggplot(indel.statistics.filtered.tib, aes(discarded_reads)) + geom_histogram()

min(indel.statistics.filtered.tib$discarded_reads)
median(indel.statistics.filtered.tib$discarded_reads)
max(indel.statistics.filtered.tib$discarded_reads)


indel.statistics.filtered.tib %>% filter(discarded_reads > .3)
```

# Bibliography
```{r citations}
cite_packages()
```


# Session Info  
```{r}
sessionInfo()
getwd()
date()
paste("Run time: ",format(Sys.time()-StartTime))
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
gc() #free up memrory and report the memory usage.
```