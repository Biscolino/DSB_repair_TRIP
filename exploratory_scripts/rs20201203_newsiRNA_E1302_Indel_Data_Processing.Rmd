--- 
title: "Indels Preprocessing"
author: "Ruben Schep"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output:
  html_document:
    theme: journal #cerulean
    highlight: monochrome
    toc: true
    toc_float: true
    code_folding: show
  editor_options:
    chunk_output_type: console
---

knitr document van Steensel lab

# Preprocessing of the indel data
# Introduction

In this script I want to prepocess the datafiles into several working dataframes.

I want one data frame in which I have the number of mutations, per sample, per barcode per indel size.
This one will be used for plotting indel patterns, calculating ratios later on and such.

I want one dataframe that contains the ratios of each barcode in each sample. These ratios will be :
This could be a long dataframe, with the following variables: Barcode, sample, ratios ...  

* Efficiency (All mutations / Total or (Total - WT sequences) / Total)  
* +1 / -7  
* Deletions / Total  
* Insertions / Total  
* +1 / (-7 + -14 + -22)  
* Barcode effiency vs Overall efficiency  

In this dataframe I would also like to have the means of the samples (here I will ignore the inhibitor treated ones)  

* Mean ratio  
* Total reads  
* Mean reads  
* Median reads  

## Description of Data

For this analysis we need the mapping and the indel data of the TRIP integrations. These
files are obtained with the crispr_trip.snake script that C. Leemans edited. This data
contains the genomic locations of the TRIP integrations (hg38) and the indel frequencies
at each integration.

The mutations were called by counting the distance between two constant regions. These
were separated by barcode. The barcodes were also filtered on the starcode, to pick out
the most abundant, and considered real, ones.

Mutations files : *genuine_mapped.table

| barcode  | type | score |
| ------- | --------- | ----- |
| TTCTATTCGCACACAA | ins | 1 |
| TTTCCCACATCAGGAG | wt | 0 |
| CCATAGTAGTGATTAC | del | -4 |

# Data importing and processing
## Path, Libraries, Parameters and Useful Functions

```{r setup, message=FALSE, warnings=FALSE}

knitr::opts_chunk$set(echo = TRUE)
Starttime <-Sys.time()

# 6-digit Date tag:
Date <- substr(gsub("-","",Sys.time()),1,8)

# libraries:
library(rtracklayer)
library(tidyr)
library(plyr)
library(dplyr)
library(data.table)
library(ggplot2)
library(report)
library(parallel)
library(gtools)
library(tibble)

## Select outdir
out.dir = paste0("/DATA/projects/DSBrepair/data/R/rs", Date, "_E1302/")
dir.create(out.dir)

in.dir.date = 20201129
in.dir = paste0("/DATA/projects/DSBrepair/data/R/rs", in.dir.date, "/")
``` 

## Custom functions
Functions used

```{r functions}
MeanExperiments <- function(mutdt) {
  
  means = mutdt[, list(norm = mean(norm), # The mean of the normalized counts for all sequences.
                       sd_norm = sd(norm), # The SD of the normalized counts (variability between exps)
                       freq = mean(freq),
                       sd_freq = sd(freq),
                       ratio_indels = mean(ratio_indels),
                       sd_ratio_indels = sd(ratio_indels),
                       count = sum(count)), # The sum of their reads
                by=c("barcode", "mutation")]
  
  reads = mutdt[, 
                list(cells = mean(cells), # The average number of theoretical cells. 
                     cells_tot = sum(cells, na.rm = TRUE), # The total number of theoretical cells.
                     sum_bc_reads = sum(sum_bc_reads, na.rm = TRUE), # The total barcode reads.
                     mean_bc_reads = mean(sum_bc_reads), # The average barcode reads. 
                     nexp = length(unique(exp))), # The amount of replicates this barcode was found in for this mean experiment.
                by=c("barcode")]
  
  # Merge the means and ratio tables (all to keep the wt sequences (mutation = 0))
  
  dt <- merge(means, reads, by = c("barcode"), all = TRUE)
  
  # print("Unique Barcodes")
  # print(length(unique(dt$barcode)))
  # print("Dimensions")
  # print(dim(dt))
  # print("nexp max")
  # print(max(dt$nexp))
  dt
}
```

## Data import
Data import from mapping. These files were generated on 30.09.2018, with a minimum of 500 reads per barcode in the mutation calling.

```{r import}
# Import files in list and make individual tables
# I use this if all the samples are good. Here however I do not use all the samples.
file.list <- list.files("/DATA/projects/DSBrepair/data/rs20201203_siRNA_6250_rs_xv/indelPCR_counts//",
                        pattern="_.*[.]count", full.names=T)

# import the data
df.list <- mclapply(file.list, 
                    read.table, 
                    mc.cores = 20, 
                    header = TRUE, 
                    stringsAsFactors = FALSE, 
                    col.names = c("barcode", "type", 
                                  "mutation", "count"))
# rename the lists
names(df.list) <- gsub(".*?/(.*?)[.]cou.*", "\\1", file.list)
# names(df.list) <- file.list
# these are the samples
head(names(df.list))
# count the sample number
n.samples <- length(df.list)
load(paste0(in.dir, "Analyis_Mapping_RSTP2_2000.RData"))

# Read metadata file
metadata <- read.table("/DATA/projects/DSBrepair/config/rs20201203_E1380_sample_list.txt", 
                       header = TRUE, 
                       stringsAsFactors = FALSE) %>% 
  mutate(replicate = paste0(exp, replicate), plasmid = ifelse(siRNA == "GFP", "GFP", "LBR2"), siRNA = ifelse(siRNA == "GFP", "-", siRNA)) %>% 
  dplyr::select(-file, -index_length, -exp, -count, -guide) %>%
  filter(PCR_type == "indelPCR") %>%
  # mutate(group = paste("mean", cell_line, plasmid, drug, ssODN, siRNA, time, sep = "_")) %>%
  data.table() 



# This is a manually curated list of mapped integrations for clone 5
# with specific PCRs and manually going though the iPCR data.
clone5barcodes <- c("AGGGCGTAAAATATTT.clone5",
                    "TATGGCTGTCGGGTAG.clone5",
                    "TGTCCCTTAGTACTTT.clone5",
                    "AGAAAATAATATGACG.clone5",
                    "CGGCCTGAAGGTCAGG.clone5",
                    "TTGAACGCGGGCTCGG.clone5",
                    "GCTAACATCACGAATC.clone5",
                    "GCGCACCCTTTAATTG.clone5",
                    "ACTGTCGAGTTGTCCG.clone5",
                    "CCGGGGACGTATGCAC.clone5",
                    "TCTTTTGAGGAGCTGA.clone5",
                    "ATATCGTTGCTGGAGA.clone5",
                    "CATCCACCACACTTCA.clone5",
                    "ACCCCTAAAGGCGCTG.clone5",
                    "ATACTATATTTAACGG.clone5",
                    "CATTTCTGATCAATAA.clone5",
                    "GAGCGCGTCACCGGGT.clone5",
                    "GTACCTCTCGATAGTG.clone5",
                    "TGGCCAATATTTGTCT.clone5")

clone5bc <- gsub("clone5", "B", clone5barcodes)

clone9bc <- c("GGTGGTGACGCCAAAG.B",
              "AGGGAAGAAGCTCGAA.B",
              "GTTTCGGCCTCCTGTA.B",
              "TTGCTCTTCCGCAGAT.B",
              "GGCTACCCTAGCACCA.B",
              "CTCCTACGACCCCTAA.B",
              "ATATTATCCCGCACCG.B",
              "GCCCAGTAATCGTACC.B",
              "AAAGGTGGGACTATCT.B",
              "ACCCAACGTCCGACCG.B",
              "ACCGAAGATGATGGCG.B",
              "CTGTCCAGTTCGACAT.B")
```

# Data processing into large data table
Set everything in a datafram that contains the barcodes, indel ratios, and efficiencies.
## extract data to list of data tables
```{r indel data table list}
# To be able to setup the functions in a general way. This means in cases where we have A
# and B samples.
mut.list = mclapply(names(df.list), function(exp){
  dt = data.table(df.list[[exp]])
  dt[, mutation := as.character(mutation)]
  dt = dt[mutation != "Inf"]
  dt[type == "ssODN" & mutation == "2", mutation := "ssODN"]
  pool = "clone5"
  dt[,barcode := paste(barcode, pool, sep = ".")]
  sum_count = data.table(exp = exp,
                         dt[, list(count=sum(count)),
                            by = c("barcode", "mutation")])
  return(sum_count)
}, mc.cores = 10)
```


## list of mapped barcodes
```{r generating mapped barcode list}
mapped_barcodes <- c(analysis.mapped.integrations.df$barcode, clone5barcodes)
```


## Combining data tables and adding metadata
```{r bind data tables}
mutations.dt = do.call(rbind, c(mut.list, fill = T))

dim(mutations.dt)

# Remove Run number from exp name and sum the read counts for these experiments.
mutations.dt[, exp := gsub("_Seq_Run[123]$", "", exp, perl = TRUE)]
metadata[, ID := gsub("_Seq_Run[123]$", "", ID, perl = TRUE)]

metadata = distinct(metadata, ID,.keep_all = TRUE) # group seq runs here also

# Sum all the seperate sequencing runs of the same samples
mutations.dt = mutations.dt[,list(count = sum(count)) , by=c("barcode","exp", "mutation")] 
dim(mutations.dt)
```
## apply cut off and filter for mapped barcodes

```{r cut off and filter data}
dim(mutations.dt)

bc_count.dt = mutations.dt[, list(sum_bc_reads = sum(count)), by=c("exp", 'barcode')]

# We used approximately 600,000 cells per experiment in the PCRs (by amount of gDNA used)
bc_count.dt = bc_count.dt[, cells:=(sum_bc_reads/sum(sum_bc_reads, na.rm = TRUE))*600000, by='exp']
mutations.cutoff.dt = mutations.dt[bc_count.dt[cells > 50, ], on = c("exp", "barcode")]

dim(mutations.cutoff.dt)

# Fill up the big data table to have 0 counts also, this will be easier to count the means and sds later on.
complete.mutations.dt = mutations.cutoff.dt %>% complete(mutation, nesting(exp, barcode), fill = list(count = 0, cells = 0, sum_bc_reads = 0)) %>% data.table()
dim(complete.mutations.dt)
sum(complete.mutations.dt$count)

complete.mutations.dt[, norm:=count/sum(count), by=exp,]
```


```{r}
# Filter the barcodes that are mapped, discard the unmapped barcodes
nonmappedmutations.dt = complete.mutations.dt[!barcode %in% mapped_barcodes]
dim(mutations.dt)
dim(nonmappedmutations.dt)
complete.mutations.mapped.dt = complete.mutations.dt[barcode %in% mapped_barcodes]
dim(complete.mutations.mapped.dt)


# Merge metadata with the mutation data table.
complete.mutations.mapped.meta.dt = complete.mutations.mapped.dt[metadata,on = c("exp" = "ID")]

# Add group column to calculate means, this is done by grouping all
# the different conditions together. 
# mutationsmeta.dt[, exp_pool := paste(cell_line, replicate, plasmid, drug, ssODN, siRNA, time, sep = "_")]
dim(complete.mutations.mapped.meta.dt)

# Clear out the global environment of these large lists
# remove(mut.list)
# remove(df.list)
# remove(mutations.dt)
# remove(mutations.cutoff.dt)
# remove(complete.mutations.dt)
# remove(complete.mutations.mapped.dt)
```

## Calculate frequencies



Next we will work on a long dataframe that will include all the ratios (deletions, insertions, +1/-7 etc) for each barcode in each sample.

I found out that some barcodes overlap in A and B but do not have the same integration sites (this has a very low chance). It would be a pitty to trash them, and I do not want to merge them as they are integrated in differente locations. I will name all the barcodes in A sample to "barcode".A and in B to "barcode".B. For this I will use the n.samples to pick out only A and only B data.

# Processing
## Filtering
Some low efficient experiments and some issues with clone5 artefacts in pooled experiments. 
```{r filtering}
# There are some elements that will be filtered out, such as bad efficiency experiemnts, shifted barcodes, and infinite mutation calling.
filtered.mutations.meta.dt <- complete.mutations.mapped.meta.dt %>%
  filter(!is.na(mutation), mutation != Inf, mutation != "<NA>") %>% # remove NA in mutation, this is the not_clear row.
  data.table()
dim(filtered.mutations.meta.dt)


. <- c(1,2,3) |> \(.) (.**./.) |> \(.) (. <<- . %% 2 %>% `[[`(2)) -> .

```

Most of the samples that have a higher average point mutation count are the negative control samples.


```{r}
filtered.mutations.meta.dt[,freq := norm/sum(norm, na.rm = TRUE), 
                          by = c("barcode","exp")]

filtered.mutations.meta.dt[!mutation%in%c(0,NA), 
                          ratio_indels := norm/sum(norm, na.rm = TRUE), 
                          by=c("barcode","exp")]
```

# Average experiments
## Means 

## Merge means with singe experiments


# Calculating frequencies and ratios 

## Calcuate frequencies
```{r calculate frequencies}
all.mutations.dt = copy(filtered.mutations.meta.dt)
all.mutations.dt[,sum_reads:=sum(count, na.rm = TRUE) , by=c("exp")] # Get the sum of all the reads per exp
```


## formatting
```{r conditions}
all.mutations.dt[, exp_pool := gsub("_-{1,4}", "", exp, perl = TRUE)]
all.mutations.dt[, exp_pool := gsub("_[AB]_", "_", exp_pool, perl = TRUE)]

# remove the .clone5 from the barcode and change it to .B (that's the origin pool of this clone)
all.mutations.dt[, "barcode" := gsub(".clone5|.clones[AB]", ".B", barcode, perl = TRUE)]

# reorder in convenient way
setcolorder(all.mutations.dt, c("exp", "exp_pool", "barcode",
                                "replicate", "clone", "plasmid", 
                                "siRNA",
                                "sum_reads", "sum_bc_reads",
                                "cells", "mutation", "count", "norm",
                                "ratio_indels", "freq"))
```

## add a color code
```{r color guide}
# Assign a color column with info on the pathway specific indels.
all.mutations.dt[, color := "other"]
all.mutations.dt[mutation == 0, color := "wt"]
all.mutations.dt[mutation == 1, color := "NHEJ"]
all.mutations.dt[mutation == -7, color := "MMEJ"]
all.mutations.dt[mutation == "ssODN", color := "SSTR"]

# # add an AB_pool qualifier per barcode (and rename pool column)
# setnames(all.mutations.dt, "pool", "cell_line")
# all.mutations.dt[, pool := gsub(".*[.]", "", barcode, perl = TRUE)]
```


# Combining large indels for plotting
## Combining large indels
```{r large indels}
# Fix large deletions for every deletion above 25
largedels <- as.character(seq(-130, -15))
columnstokeep <- names(all.mutations.dt)[!names(all.mutations.dt) %in% c("count", "ratio_indels", "freq","mutation", "color", "norm")]

mutations.large.del.dt = all.mutations.dt[mutation %in% largedels, ]
mutations.large.del.dt = mutations.large.del.dt[, lapply(.SD, sum, na.rm=TRUE), by=c(columnstokeep),
                                                .SDcols=c("count", "ratio_indels", "freq","norm")]
mutations.large.del.dt[, mutation:="<-14"]

# Fix large insertions for every insertions above 3
largeins <- as.character(seq(3, 20))
mutations.large.ins.dt = all.mutations.dt[mutation %in% largeins, ]
mutations.large.ins.dt = mutations.large.ins.dt[, lapply(.SD, sum, na.rm=TRUE), by=c(columnstokeep),
                                                .SDcols=c("count", "ratio_indels", "freq","norm")]
mutations.large.ins.dt[, mutation:=">2"]

mutations.large.del.dt
mutations.large.ins.dt

large.indels.dt = rbind(mutations.large.del.dt, mutations.large.ins.dt)

large.indels.dt[mutation %in% c(">2", "<-14"), color := "other"]

setcolorder(large.indels.dt,c("exp", "exp_pool", "barcode",
                              "replicate", "clone", "plasmid", "siRNA",
                              "sum_reads", "sum_bc_reads",
                              "cells", "mutation", "count", "norm", "ratio_indels", "freq"))
all.mutations.sep.dt = copy(all.mutations.dt)
dim(all.mutations.sep.dt)
all.mutations.trunc.dt = rbind(all.mutations.sep.dt, large.indels.dt) %>% filter(count != 0)
all.mutations.trunc.dt = all.mutations.trunc.dt[!mutation %in% largedels, ]
all.mutations.trunc.dt = all.mutations.trunc.dt[!mutation %in% largeins, ]
dim(all.mutations.trunc.dt)
```

## Formatting the combination

```{r}
muts <- unique(all.mutations.dt$mutation)
min_indel <- min(as.numeric(muts))
max_indel <- max(as.numeric(muts))
indels.odn <- c(as.character(seq(min_indel, max_indel)), "ssODN")

muts <- unique(all.mutations.trunc.dt$mutation)
min_indel <- min(as.numeric(muts[-grep("ssODN|<|>", muts)]))
max_indel <- max(as.numeric(muts[-grep("ssODN|<|>", muts)]))
indels.trunc.odn <- c("<-14", as.character(seq(min_indel, max_indel)), ">2", "ssODN")

# head(trip_tib_mut_2000)
all.mutations.trunc.dt$mutation <- factor(all.mutations.trunc.dt$mutation, levels=indels.trunc.odn)
all.mutations.dt$mutation <- factor(all.mutations.dt$mutation, levels=indels.odn)
```

## Save combinded data for indel mapping
```{r export seperate mutations}
# The mutations list that can be loaded for the indel spectra plots.
filename <- paste0(out.dir, "mutation_frequencies_trunc.RDS")
saveRDS(all.mutations.trunc.dt, file = filename)
```

We now have 3 data files that we can use for subsequent analysis.
1. The indel list of the summed experiments for the indel spectra plotting.
2. The indel data table of the read counts of the summed experiments.
3. The indel data table of the percentaage/frequencies of each indel of the summed experiments.

# Indel and pathway proportions
We will not calculate the +1 / -7 ratios, we will count the proportion of "-7" / ("-7"  + "+1"). I want to have the total insertions, total deletions and efficiences.
```{r calculate_ratios}
# Make all the sums, pct and ratios :
tib_ratios <-  as_tibble(all.mutations.dt) %>% filter(count != 0)

MMEJ <- all.mutations.dt[mutation == -7, sum(ratio_indels, na.rm = TRUE) , by=c("barcode","exp")]
tib_ratios <- full_join(tib_ratios, y = MMEJ, by = c("barcode","exp"))
names(tib_ratios)[ncol(tib_ratios)] <- "MMEJ"
tib_ratios[is.na(tib_ratios$MMEJ), "MMEJ"] = 0

NHEJ <- all.mutations.dt[mutation == 1 , sum(ratio_indels, na.rm = TRUE) , by=c("barcode","exp")]
tib_ratios <- full_join(tib_ratios, y = NHEJ, by = c("barcode","exp"))
names(tib_ratios)[ncol(tib_ratios)] <- "NHEJ"
tib_ratios[is.na(tib_ratios$NHEJ), "NHEJ"] = 0

SSTR <- all.mutations.dt[mutation == "ssODN", sum(ratio_indels, na.rm = TRUE) , by=c("barcode","exp")]
tib_ratios <- full_join(tib_ratios, y = SSTR, by = c("barcode","exp"))
names(tib_ratios)[ncol(tib_ratios)] <- "SSTR"
tib_ratios[is.na(tib_ratios$SSTR), "SSTR"] = 0

MMEJ <- all.mutations.dt[mutation == -7, sum(freq, na.rm = TRUE) , by=c("barcode","exp")]
tib_ratios <- full_join(tib_ratios, y = MMEJ, by = c("barcode","exp"))
names(tib_ratios)[ncol(tib_ratios)] <- "MMEJ_freq"
tib_ratios[is.na(tib_ratios$MMEJ_freq), "MMEJ_freq"] = 0

NHEJ <- all.mutations.dt[mutation == 1 , sum(freq, na.rm = TRUE) , by=c("barcode","exp")]
tib_ratios <- full_join(tib_ratios, y = NHEJ, by = c("barcode","exp"))
names(tib_ratios)[ncol(tib_ratios)] <- "NHEJ_freq"
tib_ratios[is.na(tib_ratios$NHEJ_freq), "NHEJ_freq"] = 0

SSTR <- all.mutations.dt[mutation == "ssODN", sum(freq, na.rm = TRUE) , by=c("barcode","exp")]
tib_ratios <- full_join(tib_ratios, y = SSTR, by = c("barcode","exp"))
names(tib_ratios)[ncol(tib_ratios)] <- "SSTR_freq"
tib_ratios[is.na(tib_ratios$SSTR_freq), "SSTR_freq"] = 0

reads_MMEJ <- all.mutations.dt[mutation%in%c(-7,-14,-22), sum(count, na.rm = TRUE) , by=c("barcode","exp")]
tib_ratios <- full_join(tib_ratios, y = reads_MMEJ, by = c("barcode","exp"))
names(tib_ratios)[ncol(tib_ratios)] <- "reads_MMEJ"

reads_NHEJ <- all.mutations.dt[mutation == 1 , sum(count, na.rm = TRUE) , by=c("barcode","exp")]
tib_ratios <- full_join(tib_ratios, y = reads_NHEJ, by = c("barcode","exp"))
names(tib_ratios)[ncol(tib_ratios)] <- "reads_NHEJ"

reads_SSTR <- all.mutations.dt[mutation == "ssODN" , sum(count, na.rm = TRUE) , by=c("barcode","exp")]
tib_ratios <- full_join(tib_ratios, y = reads_SSTR, by = c("barcode","exp"))
names(tib_ratios)[ncol(tib_ratios)] <- "reads_SSTR"

reads_NHEJ_MMEJ <- all.mutations.dt[mutation %in% c(1, -7) , sum(count, na.rm = TRUE) , by=c("barcode","exp")]
tib_ratios <- full_join(tib_ratios, y = reads_NHEJ_MMEJ, by = c("barcode","exp"))
names(tib_ratios)[ncol(tib_ratios)] <- "reads_NHEJ_MMEJ"

reads_SSTR_MMEJ <- all.mutations.dt[mutation %in% c("ssODN", -7) , sum(count, na.rm = TRUE) , by=c("barcode","exp")]
tib_ratios <- full_join(tib_ratios, y = reads_SSTR_MMEJ, by = c("barcode","exp"))
names(tib_ratios)[ncol(tib_ratios)] <- "reads_SSTR_MMEJ"

reads_SSTR_NHEJ <- all.mutations.dt[mutation %in% c(1, "ssODN") , sum(count, na.rm = TRUE) , by=c("barcode","exp")]
tib_ratios <- full_join(tib_ratios, y = reads_SSTR_NHEJ, by = c("barcode","exp"))
names(tib_ratios)[ncol(tib_ratios)] <- "reads_SSTR_NHEJ"

other_indels <- all.mutations.dt[!mutation%in%c(0, 1, -7, "ssODN"), sum(ratio_indels, na.rm = TRUE) , by=c("barcode","exp")]
tib_ratios <- full_join(tib_ratios, y = other_indels, by = c("barcode","exp"))
names(tib_ratios)[ncol(tib_ratios)] <- "other_indels"

efficiency <- all.mutations.dt[mutation == 0, 1 - freq , by=c("barcode","exp")]
tib_ratios <- full_join(tib_ratios, y = efficiency, by = c("barcode","exp"))
names(tib_ratios)[ncol(tib_ratios)] <- "efficiency"

insertions <- all.mutations.dt[mutation%in%seq(1, 15), sum(ratio_indels, na.rm = TRUE) , by=c("barcode","exp")]
tib_ratios <- full_join(tib_ratios, y = insertions, by = c("barcode","exp"))
names(tib_ratios)[ncol(tib_ratios)] <- "insertions"

deletions <- all.mutations.dt[mutation%in%seq(-120, -1), sum(ratio_indels, na.rm = TRUE) , by=c("barcode","exp")]
tib_ratios <- full_join(tib_ratios, y = deletions, by = c("barcode","exp"))
names(tib_ratios)[ncol(tib_ratios)] <- "deletions"

indel_reads <- all.mutations.dt[mutation != 0, sum(count, na.rm = TRUE) , by=c("barcode","exp")]
tib_ratios <- full_join(tib_ratios, y = indel_reads, by = c("barcode","exp"))
names(tib_ratios)[ncol(tib_ratios)] <- "indel_reads"

large_del <- all.mutations.dt[mutation%in%largedels, sum(ratio_indels, na.rm = TRUE) , by=c("barcode","exp")]
tib_ratios <- full_join(tib_ratios, y = large_del, by = c("barcode","exp"))
names(tib_ratios)[ncol(tib_ratios)] <- "large_del"

large_ins <- all.mutations.dt[mutation%in%largeins, sum(ratio_indels, na.rm = TRUE) , by=c("barcode","exp")]
tib_ratios <- full_join(tib_ratios, y = large_ins, by = c("barcode","exp"))
names(tib_ratios)[ncol(tib_ratios)] <- "large_ins"


tib_ratios = tib_ratios %>% mutate(ins_del = insertions/deletions,
                                   MMEJ_MMEJNHEJ = MMEJ/(NHEJ+MMEJ),
                                   SSTR_MMEJSSTR = SSTR/(SSTR+MMEJ),
                                   SSTR_NHEJSSTR = SSTR/(SSTR+NHEJ))

tib_RSTP2_2000_mutations <- tib_ratios
```

## Processed data export
The files will be saved in the processed data folder.
```{r export}
# The ratios data for the efficiency analysis
filename <- paste0(out.dir, "total_indel_data.RDS")
saveRDS(tib_RSTP2_2000_mutations, file = filename)
```
# Conclusions
I"m happy with the output I"ve generated. I should still work on checking what the best amount of reads is that I need for correct correlations etc.


# Bibliography
```{r citations}
cite_packages()
```


# Session Info
```{r session_info}
sessionInfo()
getwd()
date()
paste("Run time: ",format(Sys.time()-Starttime))
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
gc() #free up memrory and report the memory usage.
```
